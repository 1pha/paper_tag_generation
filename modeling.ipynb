{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['abstract', 'area', 'arxiv_id', 'task_id', 'title'],\n",
       "        num_rows: 47274\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['abstract', 'area', 'arxiv_id', 'task_id', 'title'],\n",
       "        num_rows: 2626\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['abstract', 'arxiv_id', 'title'],\n",
       "        num_rows: 2627\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "tag_dataset = load_from_disk(\"./data/paperswithcode/\")\n",
    "tag_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,AutoTokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.69k/1.69k [00:00<00:00, 1.72MB/s]\n",
      "Downloading: 100%|██████████| 899k/899k [00:01<00:00, 877kB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 468kB/s]\n",
      "Downloading: 100%|██████████| 1.36M/1.36M [00:01<00:00, 741kB/s]\n",
      "Downloading: 100%|██████████| 558M/558M [00:47<00:00, 11.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/bart-base\"\n",
    "# T5는 seq2seq 모델이므로 model을 불러올 때 AutoModelForSeq2SeqLM을 사용해야 함\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=None,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=None,\n",
    "    use_fast=True,\n",
    ")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    "    cache_dir=None,\n",
    ")\n",
    "\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs #TODO move to `arguments.py`\n",
    "max_source_length = 512\n",
    "padding = True\n",
    "truncation = True\n",
    "batch_size = 16\n",
    "num_train_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(examples):\n",
    "\n",
    "    titles = [title for title in examples['title']]\n",
    "    abstracts = [abstract for abstract in examples['abstract']]\n",
    "    target = [f\"{area}, {' '.join(task_id.split('-'))}\" for area, task_id in zip(examples['area'], examples['task_id'])]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        titles,\n",
    "        abstracts,\n",
    "        max_length=max_source_length,\n",
    "        padding=padding,\n",
    "        truncation=truncation\n",
    "    )\n",
    "    label = tokenizer(\n",
    "        target\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = label['input_ids']\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocess Training Dataset: 100%|██████████| 48/48 [00:11<00:00,  4.04ba/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tag_dataset['train']\n",
    "\n",
    "remove_columns = train_dataset.column_names\n",
    "train_dataset = train_dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=remove_columns,\n",
    "    desc=\"Preprocess Training Dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocess Evaluation(dev) Dataset: 100%|██████████| 3/3 [00:00<00:00,  3.71ba/s]\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = tag_dataset['dev']\n",
    "\n",
    "remove_columns = eval_dataset.column_names\n",
    "eval_dataset = eval_dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=remove_columns,\n",
    "    desc=\"Preprocess Evaluation(dev) Dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "sample_input_ids = torch.tensor(train_dataset['input_ids'][0]).unsqueeze(0).cuda()\n",
    "sample_attn_mask = torch.tensor(train_dataset['attention_mask'][0], dtype=torch.long).unsqueeze(0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_output = model(\n",
    "    input_ids=sample_input_ids,\n",
    "    attention_mask=sample_attn_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 506, 50265])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    pad_to_multiple_of=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir='outputs', \n",
    "    do_train=True, \n",
    "    do_eval=True, \n",
    "    predict_with_generate=True,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=2 # 모델 checkpoint를 최대 몇개 저장할지 설정\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    \"\"\"\n",
    "    postprocess는 nltk를 이용합니다.\n",
    "    Huggingface의 TemplateProcessing을 사용하여\n",
    "    정규표현식 기반으로 postprocess를 진행할 수 있지만\n",
    "    해당 미션에서는 nltk를 이용하여 간단한 후처리를 진행합니다\n",
    "    \"\"\"\n",
    "\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    # labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # decoded_labels은 rouge metric을 위한 것이며, f1/em을 구할 때 사용되지 않음\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # 간단한 post-processing\n",
    "    # decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    # formatted_predictions = [{\"id\": ex[\"id\"], \"prediction_text\": decoded_preds[i]} for i, ex in enumerate(datasets[\"validation\"].select(range(max_val_samples)))]\n",
    "    # references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets[\"validation\"].select(range(max_val_samples))]\n",
    "\n",
    "    predictions = [{\n",
    "        \"id\": ex[\"id\"],\n",
    "        \"prediction_text\": decoded_preds[i]\n",
    "    } for i, ex in enumerate(eval_dataset)]\n",
    "\n",
    "    references = [{\n",
    "        \"id\": ex[\"id\"],\n",
    "        \"answers\": tokenizer.batch_decode(ex[\"labels\"])\n",
    "    } for ex in eval_dataset]\n",
    "\n",
    "    result = metric.compute(predictions=predictions, references=references)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "train_result = trainer.train(resume_from_checkpoint=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20569cddcb8597e045cbcce2e7a427b92841b535fae025f84d70d371fd551156"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('mrc3': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
